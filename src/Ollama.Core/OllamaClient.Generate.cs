namespace Ollama.Core;

public sealed partial class OllamaClient
{
    /// <summary>
    /// Get streaming results for the given prompt.
    /// </summary>
    /// <param name="model">The model name.</param>
    /// <param name="prompt">The prompt.</param>
    /// <param name="cancellationToken">A cancellation token that can be used to cancel the initial request or ongoing streaming operation.</param>
    /// <returns>Streaming list of completion result generated by the model</returns>
    public async Task<StreamingResponse<GenerateCompletion>> GenerateCompletionStreamingAsync(string model, string prompt, CancellationToken cancellationToken = default)
    {
        return await this.GenerateCompletionStreamingAsync(new GenerateStreamingCompletionRequest
        {
            Model = model,
            Prompt = prompt
        }, cancellationToken).ConfigureAwait(false);
    }

    /// <summary>
    /// Get streaming results for the generate completion using the specified request.
    /// </summary>
    /// <param name="request">The data for this completions request.</param>
    /// <param name="cancellationToken">A cancellation token that can be used to cancel the initial request or ongoing streaming operation.</param>
    /// <returns>Streaming list of completion result generated by the model</returns>
    public async Task<StreamingResponse<GenerateCompletion>> GenerateCompletionStreamingAsync(GenerateStreamingCompletionRequest request, CancellationToken cancellationToken = default)
    {
        this._logger.LogDebug("Generate streaming completion");

        Argument.AssertNotNull(request, nameof(request));
        Argument.AssertNotNullOrWhiteSpace(request.Model, nameof(request.Model));
        Argument.AssertNotNullOrWhiteSpace(request.Prompt, nameof(request.Prompt));

        try
        {
            HttpRequestMessage requestMessage = request.ToHttpRequestMessage();

            (HttpResponseMessage HttpResponseMessage, string ResponseContent) response = await this.ExecuteHttpRequestAsync(requestMessage, cancellationToken).ConfigureAwait(false);

            this._logger.LogTrace("Generate streaming completion response content: {responseContent}", response.ResponseContent);

            return StreamingResponse<GenerateCompletion>.CreateFromResponse(response.HttpResponseMessage, (responseMessage) => ServerSendEventAsyncEnumerator<GenerateCompletion>.EnumerateFromSseStream(responseMessage, cancellationToken));
        }
        catch (HttpOperationException ex)
        {
            this._logger.LogError(ex, "Request for generate completion streaming faild. {Message}", ex.Message);

            throw;
        }
    }

    /// <summary>
    /// Get completions use specified model for the given prompt.
    /// </summary>
    /// <param name="model">The model name.</param>
    /// <param name="prompt">The prompt.</param>
    /// <param name="cancellationToken">A cancellation token that can be used to cancel the initial request or ongoing streaming operation.</param>
    /// <returns>Completion result generated by the model</returns>
    public async Task<GenerateCompletion> GenerateCompletionAsync(string model, string prompt, CancellationToken cancellationToken = default)
    {
        return await this.GenerateCompletionAsync(new GenerateCompletionRequest
        {
            Model = model,
            Prompt = prompt
        }, cancellationToken).ConfigureAwait(false);
    }

    /// <summary>
    /// Get completions as configured for the given request.
    /// </summary>
    /// <param name="request">The data for this completions request.</param>
    /// <param name="cancellationToken">A cancellation token that can be used to cancel the initial request or ongoing streaming operation.</param>
    /// <returns>Completion result generated by the model</returns>
    /// <exception cref="DeserializationException">When deserialize the response is null.</exception>
    public async Task<GenerateCompletion> GenerateCompletionAsync(GenerateCompletionRequest request, CancellationToken cancellationToken = default)
    {
        Argument.AssertNotNull(request, nameof(request));
        Argument.AssertNotNullOrWhiteSpace(request.Model, nameof(request.Model));
        Argument.AssertNotNullOrWhiteSpace(request.Prompt, nameof(request.Prompt));

        this._logger.LogDebug("Generate completion");

        try
        {
            HttpRequestMessage requestMessage = request.ToHttpRequestMessage();

            (HttpResponseMessage httpResponseMessage, string responseContent) = await this.ExecuteHttpRequestAsync(requestMessage, cancellationToken).ConfigureAwait(false);

            this._logger.LogTrace("Generate completion response content: {responseContent}", responseContent);

            GenerateCompletion? generateCompletion = responseContent.FromJson<GenerateCompletion>();

            return generateCompletion is null || string.IsNullOrWhiteSpace(generateCompletion.Model)
                ? throw new DeserializationException(responseContent, message: $"The generate completion response content: '{responseContent}' cannot be deserialize to an instance of {nameof(GenerateCompletion)}.", innerException: null)
                : generateCompletion;
        }
        catch (HttpOperationException ex)
        {
            this._logger.LogError(ex, "Request for generate completion faild. {Message}", ex.Message);

            throw;
        }
    }

    /// <summary>
    /// Load the speficied model into memory.
    /// </summary>
    /// <param name="model">The model name.</param>
    /// <param name="cancellationToken">A cancellation token that can be used to cancel the initial request or ongoing streaming operation.</param>
    /// <returns>The model loaded response.</returns>
    /// <exception cref="DeserializationException">When deserialize the response is null.</exception>
    public async Task<LoadModel> LoadModelAsync(string model, CancellationToken cancellationToken = default)
    {
        Argument.AssertNotNull(model, nameof(model));

        this._logger.LogDebug("Load model: {model}", model);

        try
        {
            LoadModelRequest request = new()
            {
                Model = model
            };

            HttpRequestMessage requestMessage = request.ToHttpRequestMessage();

            (HttpResponseMessage httpResponseMessage, string responseContent) = await this.ExecuteHttpRequestAsync(requestMessage, cancellationToken).ConfigureAwait(false);

            this._logger.LogTrace("Load model response content: {responseContent}", responseContent);

            LoadModel? loadModel = responseContent.FromJson<LoadModel>();

            return loadModel is null || string.IsNullOrWhiteSpace(loadModel.Model)
                ? throw new DeserializationException(responseContent, message: $"The load model response content: '{responseContent}' cannot be deserialize to an instance of {nameof(LoadModel)}.", innerException: null)
                : loadModel;
        }
        catch (HttpOperationException ex)
        {
            this._logger.LogError(ex, "Request for load model faild. {Message}", ex.Message);

            throw;
        }
    }
}